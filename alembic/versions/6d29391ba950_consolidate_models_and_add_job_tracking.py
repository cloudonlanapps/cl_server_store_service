"""consolidate_models_and_add_job_tracking

Revision ID: 6d29391ba950
Revises: 00268ae3f7cc
Create Date: 2026-01-22 16:06:07.595230

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import sqlite

# revision identifiers, used by Alembic.
revision: str = '6d29391ba950'
down_revision: Union[str, None] = '00268ae3f7cc'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    conn = op.get_bind()
    inspector = sa.inspect(conn)
    if inspector.has_table('queue_entries'):
        op.drop_table('queue_entries')
    if inspector.has_table('jobs'):
        op.drop_table('jobs')
    
    # Check entities table
    entities_indexes = [i['name'] for i in inspector.get_indexes('entities')]
    entities_fks = [fk['name'] for fk in inspector.get_foreign_keys('entities')]
    
    # Backfill NULLs for non-nullable columns before altering
    op.execute("UPDATE entities SET is_collection = 0 WHERE is_collection IS NULL")
    op.execute("UPDATE entities SET is_deleted = 0 WHERE is_deleted IS NULL")

    with op.batch_alter_table('entities', schema=None) as batch_op:
        if 'ix_entities_parent_id' not in entities_indexes:
            batch_op.create_index(batch_op.f('ix_entities_parent_id'), ['parent_id'], unique=False)
        if 'fk_entities_parent_id_entities' not in entities_fks and None not in entities_fks: 
            # Note: None check might be needed if previous FK was unnamed, but we are fixing it now.
            # Safe to assume if named one is missing, we create it.
            batch_op.create_foreign_key('fk_entities_parent_id_entities', 'entities', ['parent_id'], ['id'])
        
        # Enforce non-nullable constraints
        batch_op.alter_column('is_collection', existing_type=sa.Boolean(), nullable=False, server_default=sa.text('0'))
        batch_op.alter_column('is_deleted', existing_type=sa.Boolean(), nullable=False, server_default=sa.text('0'))

    # Check entities_version table
    entities_version_indexes = [i['name'] for i in inspector.get_indexes('entities_version')]
    
    with op.batch_alter_table('entities_version', schema=None) as batch_op:
        if 'ix_entities_version_parent_id' not in entities_version_indexes:
            batch_op.create_index(batch_op.f('ix_entities_version_parent_id'), ['parent_id'], unique=False)

    # Check image_intelligence table
    img_columns = [c['name'] for c in inspector.get_columns('image_intelligence')]
    
    with op.batch_alter_table('image_intelligence', schema=None) as batch_op:
        if 'face_detection_job_id' not in img_columns:
            batch_op.add_column(sa.Column('face_detection_job_id', sa.String(), nullable=True))
        if 'clip_job_id' not in img_columns:
            batch_op.add_column(sa.Column('clip_job_id', sa.String(), nullable=True))
        if 'dino_job_id' not in img_columns:
            batch_op.add_column(sa.Column('dino_job_id', sa.String(), nullable=True))
        if 'processing_status' not in img_columns:
            batch_op.add_column(sa.Column('processing_status', sa.String(), nullable=False, server_default='pending'))
        if 'face_embedding_job_ids' not in img_columns:
            batch_op.add_column(sa.Column('face_embedding_job_ids', sa.JSON(), nullable=True))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    conn = op.get_bind()
    inspector = sa.inspect(conn)
    img_columns = [c['name'] for c in inspector.get_columns('image_intelligence')]
    entities_version_indexes = [i['name'] for i in inspector.get_indexes('entities_version')]
    entities_fks = [fk['name'] for fk in inspector.get_foreign_keys('entities')]
    entities_indexes = [i['name'] for i in inspector.get_indexes('entities')]

    with op.batch_alter_table('image_intelligence', schema=None) as batch_op:
        # Check availability before dropping
        if 'processing_status' in img_columns:
            batch_op.drop_column('processing_status')
        if 'dino_job_id' in img_columns:
            batch_op.drop_column('dino_job_id')
        if 'clip_job_id' in img_columns:
            batch_op.drop_column('clip_job_id')
        if 'face_detection_job_id' in img_columns:
            batch_op.drop_column('face_detection_job_id')
        if 'face_embedding_job_ids' in img_columns:
            batch_op.drop_column('face_embedding_job_ids')

    with op.batch_alter_table('entities_version', schema=None) as batch_op:
        if 'ix_entities_version_parent_id' in entities_version_indexes:
            batch_op.drop_index(batch_op.f('ix_entities_version_parent_id'))

    with op.batch_alter_table('entities', schema=None) as batch_op:
        if 'fk_entities_parent_id_entities' in entities_fks:
            batch_op.drop_constraint('fk_entities_parent_id_entities', type_='foreignkey')
        if 'ix_entities_parent_id' in entities_indexes:
            batch_op.drop_index(batch_op.f('ix_entities_parent_id'))
        # Revert nullable constraints (making them nullable again)
        # Note: altering to nullable=True is always safe data-wise
        batch_op.alter_column('is_collection', existing_type=sa.Boolean(), nullable=True)
        batch_op.alter_column('is_deleted', existing_type=sa.Boolean(), nullable=True)
    op.create_table('jobs',
    sa.Column('id', sa.INTEGER(), nullable=False),
    sa.Column('job_id', sa.VARCHAR(), nullable=False),
    sa.Column('task_type', sa.VARCHAR(), nullable=False),
    sa.Column('priority', sa.INTEGER(), nullable=False),
    sa.Column('params', sqlite.JSON(), nullable=False),
    sa.Column('output', sqlite.JSON(), nullable=True),
    sa.Column('status', sa.VARCHAR(), nullable=False),
    sa.Column('progress', sa.INTEGER(), nullable=False),
    sa.Column('created_at', sa.INTEGER(), nullable=False),
    sa.Column('started_at', sa.INTEGER(), nullable=True),
    sa.Column('completed_at', sa.INTEGER(), nullable=True),
    sa.Column('error_message', sa.TEXT(), nullable=True),
    sa.Column('retry_count', sa.INTEGER(), nullable=False),
    sa.Column('max_retries', sa.INTEGER(), nullable=False),
    sa.Column('created_by', sa.VARCHAR(), nullable=True),
    sa.Column('updated_at', sa.INTEGER(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_jobs_status'), 'jobs', ['status'], unique=False)
    op.create_index(op.f('ix_jobs_job_id'), 'jobs', ['job_id'], unique=1)
    op.create_index(op.f('ix_jobs_created_by'), 'jobs', ['created_by'], unique=False)
    op.create_index(op.f('ix_jobs_created_at'), 'jobs', ['created_at'], unique=False)
    op.create_table('queue_entries',
    sa.Column('id', sa.INTEGER(), nullable=False),
    sa.Column('job_id', sa.VARCHAR(), nullable=False),
    sa.Column('priority', sa.INTEGER(), nullable=False),
    sa.Column('enqueued_at', sa.INTEGER(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_queue_entries_job_id'), 'queue_entries', ['job_id'], unique=1)
    op.create_index(op.f('ix_queue_entries_enqueued_at'), 'queue_entries', ['enqueued_at'], unique=False)
    # ### end Alembic commands ###
